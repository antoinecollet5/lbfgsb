{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Number of calls and results benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Speed and memory consumption benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- import some functions from stochopy to test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python lbfgsb works with numpy arrays\n",
    "import numpy as np\n",
    "from lbfgsb import minimize_lbfgsb\n",
    "from scipy.optimize import minimize\n",
    "import logging\n",
    "from lbfgsb.benchmarks import (\n",
    "    ackley,\n",
    "    ackley_grad,\n",
    "    beale,\n",
    "    beale_grad,\n",
    "    griewank,\n",
    "    griewank_grad,\n",
    "    quartic,\n",
    "    quartic_grad,\n",
    "    rastrigin,\n",
    "    rastrigin_grad,\n",
    "    rosenbrock,\n",
    "    rosenbrock_grad,\n",
    "    sphere,\n",
    "    sphere_grad,\n",
    "    styblinski_tang,\n",
    "    styblinski_tang_grad,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from lbfgsb.types import NDArrayFloat\n",
    "\n",
    "\n",
    "def plot_2d(lb: NDArrayFloat, ub: NDArrayFloat, f: Callable) -> None:\n",
    "    x = np.linspace(lb, ub)\n",
    "    plt.contourf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a logger for the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :test the main logger\n",
      "INFO:L-BFGS-B:test the solver logger\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Test\")\n",
    "main_logger = logging.getLogger(\" -MAIN- \")\n",
    "main_logger.setLevel(level=logging.INFO)\n",
    "main_logger.info(\"test the main logger\")\n",
    "\n",
    "solver_logger = logging.getLogger(\"L-BFGS-B\")\n",
    "solver_logger.setLevel(level=logging.INFO)\n",
    "solver_logger.info(\"test the solver logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iprint = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First example: min x^{\\mathrm{T}}x such that x>=1. Optimal solution hits the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad(x):\n",
    "    return 10 * x[0] ** 2 + x[1] ** 2\n",
    "\n",
    "\n",
    "def grad_quad(x):\n",
    "    return np.array([20 * x[0], 2 * x[1]])\n",
    "\n",
    "\n",
    "ftol = 1e-5\n",
    "gtol = 1e-5\n",
    "l = np.array([1.0, 1.0])\n",
    "u = np.array([np.inf, np.inf])\n",
    "bounds = np.array((l, u)).T\n",
    "x0 = np.array([5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., inf])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :====================== Quadratic example ======================\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :Theoretical optimal value: \n",
      "INFO: -MAIN- :{'x': array([1, 1]), 'f': 11, 'df': array([20,  2])}\n",
      "INFO: -MAIN- :Optimal value found: \n",
      "INFO: -MAIN- :  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  success: True\n",
      "   status: 1\n",
      "      fun: 11.0\n",
      "        x: [ 1.000e+00  1.000e+00]\n",
      "      nit: 2\n",
      "      jac: [ 2.000e+01  2.000e+00]\n",
      "     nfev: 3\n",
      "     njev: 3\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "main_logger.info(\"====================== Quadratic example ======================\")\n",
    "opt_quad = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=quad,\n",
    "    jac=grad_quad,\n",
    "    bounds=bounds,\n",
    "    ftol=ftol,\n",
    "    gtol=gtol,\n",
    "    iprint=iprint,\n",
    "    logger=solver_logger,\n",
    ")\n",
    "main_logger.info(\"\")\n",
    "main_logger.info(\"\")\n",
    "xOpt = np.array([1, 1])\n",
    "theoOpt = {\"x\": xOpt, \"f\": quad(xOpt), \"df\": grad_quad(xOpt)}\n",
    "main_logger.info(\"Theoretical optimal value: \")\n",
    "main_logger.info(theoOpt)\n",
    "main_logger.info(\"Optimal value found: \")\n",
    "main_logger.info(opt_quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 11.0\n",
       "        x: [ 1.000e+00  1.000e+00]\n",
       "      nit: 2\n",
       "      jac: [ 2.000e+01  2.000e+00]\n",
       "     nfev: 3\n",
       "     njev: 3\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(\n",
    "    quad,\n",
    "    x0,\n",
    "    jac=grad_quad,\n",
    "    bounds=bounds,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"gtol\": gtol, \"ftol\": ftol, \"disp\": iprint, \"iprint\": iprint},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second example: Ackley function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([-2, -2, -1])\n",
    "u = np.array([2, 2, 3])\n",
    "bounds = np.array((l, u)).T\n",
    "# x0 = np.array([0.12, 0.12])\n",
    "x0 = np.array([-0.8, -1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acollet/workspace/lbfgsb/lbfgsb/linesearch.py:247: UserWarning: WARNING: dcsrch did not converge within max iterations\n",
      "  warnings.warn(task.decode(\"utf-8\"))\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :Theoretical optimal value: \n",
      "INFO: -MAIN- :  message: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  success: False\n",
      "   status: 2\n",
      "      fun: 3.4493521599753656\n",
      "        x: [-8.000e-01 -1.000e+00  1.000e-01]\n",
      "      nit: 0\n",
      "      jac: [-3.232e+00 -1.550e+00 -1.076e+00]\n",
      "     nfev: 21\n",
      "     njev: 21\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "INFO: -MAIN- :Optimal value found: \n"
     ]
    }
   ],
   "source": [
    "opt_akley = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=ackley,\n",
    "    jac=ackley_grad,\n",
    "    bounds=bounds,\n",
    "    maxcor=5,\n",
    "    ftol=ftol,\n",
    "    gtol=gtol,\n",
    "    iprint=iprint,\n",
    "    ftol_linesearch=1e-3,\n",
    "    gtol_linesearch=0.9,\n",
    "    xtol_linesearch=0.1,\n",
    "    logger=solver_logger,\n",
    ")\n",
    "main_logger.info(\"\")\n",
    "main_logger.info(\"\")\n",
    "theoOpt = {\"x\": np.array([1, 1, 2]), \"f\": 0, \"df\": ackley_grad(np.array([1, 1, 3]))}\n",
    "main_logger.info(\"Theoretical optimal value: \")\n",
    "main_logger.info(opt_akley)\n",
    "main_logger.info(\"Optimal value found: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: ABNORMAL_TERMINATION_IN_LNSRCH\n",
       "  success: False\n",
       "   status: 2\n",
       "      fun: 3.4493521599753656\n",
       "        x: [-8.000e-01 -1.000e+00  1.000e-01]\n",
       "      nit: 0\n",
       "      jac: [-3.232e+00 -1.550e+00 -1.076e+00]\n",
       "     nfev: 21\n",
       "     njev: 21\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(\n",
    "    x0=x0,\n",
    "    fun=ackley,\n",
    "    jac=ackley_grad,\n",
    "    bounds=bounds,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options=dict(\n",
    "        maxcor=5,\n",
    "        ftol=ftol,\n",
    "        gtol=gtol,\n",
    "        iprint=iprint,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second example : min Rosenbrock function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([-2, -2])\n",
    "u = np.array([2, 2])\n",
    "bounds = np.array((l, u)).T\n",
    "# x0 = np.array([0.12, 0.12])\n",
    "x0 = np.array([-0.8, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :Theoretical optimal value: \n",
      "INFO: -MAIN- :{'x': array([1, 1]), 'f': 0, 'df': array([0., 0.])}\n",
      "INFO: -MAIN- :Optimal value found: \n"
     ]
    }
   ],
   "source": [
    "opt_rosenbrock = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=rosenbrock,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    maxcor=5,\n",
    "    ftol=ftol,\n",
    "    gtol=gtol,\n",
    "    iprint=iprint,\n",
    "    ftol_linesearch=1e-3,\n",
    "    gtol_linesearch=0.9,\n",
    "    xtol_linesearch=0.1,\n",
    "    logger=solver_logger,\n",
    ")\n",
    "main_logger.info(\"\")\n",
    "main_logger.info(\"\")\n",
    "theoOpt = {\"x\": np.array([1, 1]), \"f\": 0, \"df\": rosenbrock_grad(np.array([1, 1]))}\n",
    "main_logger.info(\"Theoretical optimal value: \")\n",
    "main_logger.info(theoOpt)\n",
    "main_logger.info(\"Optimal value found: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 3.8738696318949315e-07\n",
      "        x: [ 9.994e-01  9.988e-01]\n",
      "      nit: 19\n",
      "      jac: [-1.603e-03  1.794e-04]\n",
      "     nfev: 24\n",
      "     njev: 24\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "main_logger.info(opt_rosenbrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00160319,  0.00017937])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosenbrock_grad(opt_rosenbrock.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_rosenbrock_sp = minimize(\n",
    "    rosenbrock,\n",
    "    x0,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"gtol\": gtol, \"ftol\": ftol, \"iprint\": iprint, \"maxcor\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 3.87386963183571e-07\n",
       "        x: [ 9.994e-01  9.988e-01]\n",
       "      nit: 19\n",
       "      jac: [-1.603e-03  1.794e-04]\n",
       "     nfev: 24\n",
       "     njev: 24\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_rosenbrock_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third example : min Beale function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beale2(x):\n",
    "    return (\n",
    "        (1.5 - x[0] + x[0] * x[1]) ** 2\n",
    "        + (2.25 - x[0] + x[0] * x[1] ** 2) ** 2\n",
    "        + (2.625 - x[0] + x[0] * x[1] ** 3) ** 2\n",
    "    )\n",
    "\n",
    "\n",
    "def beale_grad2(x):\n",
    "    y1 = x[1]\n",
    "    y2 = y1 * y1\n",
    "    y3 = y2 * y1\n",
    "    f1 = 1.5 - x[0] + x[0] * y1\n",
    "    f2 = 2.25 - x[0] + x[0] * y2\n",
    "    f3 = 2.625 - x[0] + x[0] * y3\n",
    "\n",
    "    return np.array(\n",
    "        [\n",
    "            2 * (y1 - 1) * f1 + 2 * (y2 - 1) * f2 + 2 * (y3 - 1) * f3,\n",
    "            2 * x[0] * f1 + 4 * x[0] * y1 * f2 + 6 * x[0] * y2 * f3,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "ftol = 1e-14\n",
    "gtol = 1e-10\n",
    "l = -4.5 * np.ones(2)\n",
    "u = -l\n",
    "bounds = np.array((l, u)).T\n",
    "x0 = np.array([2.5, -1.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :Theoretical optimal value: \n",
      "INFO: -MAIN- :{'x': array([3. , 0.5]), 'f': 0.0, 'df': array([0., 0.])}\n",
      "INFO: -MAIN- :Optimal value found: \n"
     ]
    }
   ],
   "source": [
    "opt_beale = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=beale,\n",
    "    jac=beale_grad,\n",
    "    bounds=bounds,\n",
    "    ftol=ftol,\n",
    "    gtol=gtol,\n",
    "    logger=solver_logger,\n",
    "    iprint=iprint,\n",
    ")\n",
    "main_logger.info(\"\")\n",
    "main_logger.info(\"\")\n",
    "theoOpt = {\n",
    "    \"x\": np.array([3, 0.5]),\n",
    "    \"f\": beale(np.array([3, 0.5])),\n",
    "    \"df\": beale_grad(np.array([3, 0.5])),\n",
    "}\n",
    "main_logger.info(\"Theoretical optimal value: \")\n",
    "main_logger.info(theoOpt)\n",
    "main_logger.info(\"Optimal value found: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 1.4337068336583181e-21\n",
      "        x: [ 3.000e+00  5.000e-01]\n",
      "      nit: 16\n",
      "      jac: [-7.089e-11  1.797e-10]\n",
      "     nfev: 20\n",
      "     njev: 20\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "main_logger.info(opt_beale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_beale_sp = minimize(\n",
    "    beale,\n",
    "    x0,\n",
    "    jac=beale_grad,\n",
    "    bounds=bounds,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"gtol\": gtol, \"ftol\": ftol, \"iprint\": iprint},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 1.4337068336583181e-21\n",
       "        x: [ 3.000e+00  5.000e-01]\n",
       "      nit: 16\n",
       "      jac: [-7.089e-11  1.797e-10]\n",
       "     nfev: 20\n",
       "     njev: 20\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_beale_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparision of convergence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
