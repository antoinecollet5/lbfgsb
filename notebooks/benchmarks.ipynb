{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- import some functions from stochopy to test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python lbfgsb works with numpy arrays\n",
    "import numpy as np\n",
    "from lbfgsb import minimize_lbfgsb\n",
    "from scipy.optimize import minimize\n",
    "import logging\n",
    "from lbfgsb.benchmarks import (\n",
    "    ackley,\n",
    "    ackley_grad,\n",
    "    beale,\n",
    "    beale_grad,\n",
    "    griewank,\n",
    "    griewank_grad,\n",
    "    quartic,\n",
    "    quartic_grad,\n",
    "    rastrigin,\n",
    "    rastrigin_grad,\n",
    "    rosenbrock,\n",
    "    rosenbrock_grad,\n",
    "    sphere,\n",
    "    sphere_grad,\n",
    "    styblinski_tang,\n",
    "    styblinski_tang_grad,\n",
    ")\n",
    "\n",
    "from lbfgsb.utils import get_grad_projection_inf_norm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from lbfgsb.types import NDArrayFloat\n",
    "\n",
    "\n",
    "def plot_2d(lb: NDArrayFloat, ub: NDArrayFloat, f: Callable) -> None:\n",
    "    x = np.linspace(lb, ub)\n",
    "    plt.contourf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a logger for the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :test the main logger\n",
      "INFO:L-BFGS-B:test the solver logger\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Test\")\n",
    "main_logger = logging.getLogger(\" -MAIN- \")\n",
    "main_logger.setLevel(level=logging.INFO)\n",
    "main_logger.info(\"test the main logger\")\n",
    "\n",
    "solver_logger = logging.getLogger(\"L-BFGS-B\")\n",
    "solver_logger.setLevel(level=logging.INFO)\n",
    "solver_logger.info(\"test the solver logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iprint = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First example: min x^{\\mathrm{T}}x such that x>=1. Optimal solution hits the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad(x):\n",
    "    return 10 * x[0] ** 2 + x[1] ** 2\n",
    "\n",
    "\n",
    "def grad_quad(x):\n",
    "    return np.array([20 * x[0], 2 * x[1]])\n",
    "\n",
    "\n",
    "ftol = 1e-5\n",
    "gtol = 1e-5\n",
    "l = np.array([1.0, 1.0])\n",
    "u = np.array([np.inf, np.inf])\n",
    "bounds = np.array((l, u)).T\n",
    "x0 = np.array([5.0, 5.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., inf])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :====================== Quadratic example ======================\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :Theoretical optimal value: \n",
      "INFO: -MAIN- :{'x': array([1, 1]), 'f': np.int64(11), 'df': array([20,  2])}\n",
      "INFO: -MAIN- :Optimal value found: \n",
      "INFO: -MAIN- :  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  success: True\n",
      "   status: 1\n",
      "      fun: 11.0\n",
      "        x: [ 1.000e+00  1.000e+00]\n",
      "      nit: 2\n",
      "      jac: [ 2.000e+01  2.000e+00]\n",
      "     nfev: 3\n",
      "     njev: 3\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "main_logger.info(\"====================== Quadratic example ======================\")\n",
    "opt_quad = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=quad,\n",
    "    jac=grad_quad,\n",
    "    bounds=bounds,\n",
    "    ftol=ftol,\n",
    "    gtol=gtol,\n",
    "    iprint=iprint,\n",
    "    logger=solver_logger,\n",
    ")\n",
    "main_logger.info(\"\")\n",
    "main_logger.info(\"\")\n",
    "xOpt = np.array([1, 1])\n",
    "theoOpt = {\"x\": xOpt, \"f\": quad(xOpt), \"df\": grad_quad(xOpt)}\n",
    "main_logger.info(\"Theoretical optimal value: \")\n",
    "main_logger.info(theoOpt)\n",
    "main_logger.info(\"Optimal value found: \")\n",
    "main_logger.info(opt_quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 11.0\n",
       "        x: [ 1.000e+00  1.000e+00]\n",
       "      nit: 2\n",
       "      jac: [ 2.000e+01  2.000e+00]\n",
       "     nfev: 3\n",
       "     njev: 3\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(\n",
    "    quad,\n",
    "    x0,\n",
    "    jac=grad_quad,\n",
    "    bounds=bounds,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"gtol\": gtol, \"ftol\": ftol},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second example: Ackley function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([-2, -2, -1])\n",
    "u = np.array([2, 2, 3])\n",
    "bounds = np.array((l, u)).T\n",
    "# x0 = np.array([0.12, 0.12])\n",
    "x0 = np.array([-0.8, -1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :Theoretical optimal value: \n",
      "INFO: -MAIN- :  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 3.4493521599753656\n",
      "        x: [-8.000e-01 -1.000e+00  1.000e-01]\n",
      "      nit: 0\n",
      "      jac: [-3.232e+00 -1.550e+00 -1.076e+00]\n",
      "     nfev: 21\n",
      "     njev: 21\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "INFO: -MAIN- :Optimal value found: \n"
     ]
    }
   ],
   "source": [
    "opt_akley = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=ackley,\n",
    "    jac=ackley_grad,\n",
    "    bounds=bounds,\n",
    "    maxcor=5,\n",
    "    ftol=ftol,\n",
    "    gtol=gtol,\n",
    "    iprint=iprint,\n",
    "    ftol_linesearch=1e-3,\n",
    "    gtol_linesearch=0.9,\n",
    "    xtol_linesearch=0.1,\n",
    "    logger=solver_logger,\n",
    ")\n",
    "main_logger.info(\"\")\n",
    "main_logger.info(\"\")\n",
    "theoOpt = {\"x\": np.array([1, 1, 2]), \"f\": 0, \"df\": ackley_grad(np.array([1, 1, 3]))}\n",
    "main_logger.info(\"Theoretical optimal value: \")\n",
    "main_logger.info(opt_akley)\n",
    "main_logger.info(\"Optimal value found: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: ABNORMAL: \n",
       "  success: False\n",
       "   status: 2\n",
       "      fun: 3.4493521599753656\n",
       "        x: [-8.000e-01 -1.000e+00  1.000e-01]\n",
       "      nit: 0\n",
       "      jac: [-3.232e+00 -1.550e+00 -1.076e+00]\n",
       "     nfev: 21\n",
       "     njev: 21\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(\n",
    "    x0=x0,\n",
    "    fun=ackley,\n",
    "    jac=ackley_grad,\n",
    "    bounds=bounds,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options=dict(\n",
    "        maxcor=5,\n",
    "        ftol=ftol,\n",
    "        gtol=gtol,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second example : min Rosenbrock function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([-2, -2])\n",
    "u = np.array([2, 2])\n",
    "bounds = np.array((l, u)).T\n",
    "# x0 = np.array([0.12, 0.12])\n",
    "x0 = np.array([-0.8, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :Theoretical optimal value: \n",
      "INFO: -MAIN- :{'x': array([1, 1]), 'f': 0, 'df': array([0., 0.])}\n",
      "INFO: -MAIN- :Optimal value found: \n"
     ]
    }
   ],
   "source": [
    "opt_rosenbrock = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=rosenbrock,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    maxcor=5,\n",
    "    ftol=ftol,\n",
    "    gtol=gtol,\n",
    "    iprint=iprint,\n",
    "    ftol_linesearch=1e-3,\n",
    "    gtol_linesearch=0.9,\n",
    "    xtol_linesearch=0.1,\n",
    "    logger=solver_logger,\n",
    ")\n",
    "main_logger.info(\"\")\n",
    "main_logger.info(\"\")\n",
    "theoOpt = {\"x\": np.array([1, 1]), \"f\": 0, \"df\": rosenbrock_grad(np.array([1, 1]))}\n",
    "main_logger.info(\"Theoretical optimal value: \")\n",
    "main_logger.info(theoOpt)\n",
    "main_logger.info(\"Optimal value found: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 3.8738696325664974e-07\n",
      "        x: [ 9.994e-01  9.988e-01]\n",
      "      nit: 18\n",
      "      jac: [-1.603e-03  1.794e-04]\n",
      "     nfev: 24\n",
      "     njev: 24\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "main_logger.info(opt_rosenbrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00160319,  0.00017937])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosenbrock_grad(opt_rosenbrock.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ancollet\\AppData\\Local\\Temp\\ipykernel_32856\\1020373109.py:1: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "  opt_rosenbrock_sp = minimize(\n"
     ]
    }
   ],
   "source": [
    "opt_rosenbrock_sp = minimize(\n",
    "    rosenbrock,\n",
    "    x0,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"gtol\": gtol, \"ftol\": ftol, \"iprint\": iprint, \"maxcor\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 3.873869631473485e-07\n",
       "        x: [ 9.994e-01  9.988e-01]\n",
       "      nit: 19\n",
       "      jac: [-1.603e-03  1.794e-04]\n",
       "     nfev: 24\n",
       "     njev: 24\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_rosenbrock_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third example : min Beale function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beale2(x):\n",
    "    return (\n",
    "        (1.5 - x[0] + x[0] * x[1]) ** 2\n",
    "        + (2.25 - x[0] + x[0] * x[1] ** 2) ** 2\n",
    "        + (2.625 - x[0] + x[0] * x[1] ** 3) ** 2\n",
    "    )\n",
    "\n",
    "\n",
    "def beale_grad2(x):\n",
    "    y1 = x[1]\n",
    "    y2 = y1 * y1\n",
    "    y3 = y2 * y1\n",
    "    f1 = 1.5 - x[0] + x[0] * y1\n",
    "    f2 = 2.25 - x[0] + x[0] * y2\n",
    "    f3 = 2.625 - x[0] + x[0] * y3\n",
    "\n",
    "    return np.array(\n",
    "        [\n",
    "            2 * (y1 - 1) * f1 + 2 * (y2 - 1) * f2 + 2 * (y3 - 1) * f3,\n",
    "            2 * x[0] * f1 + 4 * x[0] * y1 * f2 + 6 * x[0] * y2 * f3,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "ftol = 1e-14\n",
    "gtol = 1e-10\n",
    "l = -4.5 * np.ones(2)\n",
    "u = -l\n",
    "bounds = np.array((l, u)).T\n",
    "x0 = np.array([2.5, -1.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :\n",
      "INFO: -MAIN- :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :Theoretical optimal value: \n",
      "INFO: -MAIN- :{'x': array([3. , 0.5]), 'f': np.float64(0.0), 'df': array([0., 0.])}\n",
      "INFO: -MAIN- :Optimal value found: \n"
     ]
    }
   ],
   "source": [
    "opt_beale = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=beale,\n",
    "    jac=beale_grad,\n",
    "    bounds=bounds,\n",
    "    ftol=ftol,\n",
    "    gtol=gtol,\n",
    "    logger=solver_logger,\n",
    "    iprint=iprint,\n",
    ")\n",
    "main_logger.info(\"\")\n",
    "main_logger.info(\"\")\n",
    "theoOpt = {\n",
    "    \"x\": np.array([3, 0.5]),\n",
    "    \"f\": beale(np.array([3, 0.5])),\n",
    "    \"df\": beale_grad(np.array([3, 0.5])),\n",
    "}\n",
    "main_logger.info(\"Theoretical optimal value: \")\n",
    "main_logger.info(theoOpt)\n",
    "main_logger.info(\"Optimal value found: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: -MAIN- :  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 1.4336936823116482e-21\n",
      "        x: [ 3.000e+00  5.000e-01]\n",
      "      nit: 15\n",
      "      jac: [-7.089e-11  1.797e-10]\n",
      "     nfev: 20\n",
      "     njev: 20\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "main_logger.info(opt_beale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ancollet\\AppData\\Local\\Temp\\ipykernel_32856\\1355717965.py:1: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "  opt_beale_sp = minimize(\n"
     ]
    }
   ],
   "source": [
    "opt_beale_sp = minimize(\n",
    "    beale,\n",
    "    x0,\n",
    "    jac=beale_grad,\n",
    "    bounds=bounds,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"gtol\": gtol, \"ftol\": ftol, \"iprint\": iprint},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 1.4337282180350256e-21\n",
       "        x: [ 3.000e+00  5.000e-01]\n",
       "      nit: 16\n",
       "      jac: [-7.089e-11  1.797e-10]\n",
       "     nfev: 20\n",
       "     njev: 20\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_beale_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparision of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:L-BFGS-B:At iterate 0 , f= 1.404e+217 , |proj g|= 1.404e+218\n",
      "INFO:L-BFGS-B:\n",
      "\n",
      "INFO:L-BFGS-B:ITERATION 1\n",
      "\n",
      "INFO:L-BFGS-B:---------------- CAUCHY entered-------------------\n",
      "INFO:L-BFGS-B:---------------- exit CAUCHY----------------------\n",
      "INFO:L-BFGS-B:1 variables are free at GCP, iter = 1\n",
      "INFO:L-BFGS-B:Iteration #0 (max: 50): ||x||=5.000e+01, f(x)=1.404e+217, ||jac(x)||=1.404e+218, cdt_arret=1.404e+218 (eps=1.000e-05)\n",
      "INFO:L-BFGS-B:  message: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  success: False\n",
      "   status: 2\n",
      "      fun: 1.4035922178528375e+217\n",
      "        x: [-5.000e+01]\n",
      "      nit: 0\n",
      "      jac: [-1.404e+218]\n",
      "     nfev: 6\n",
      "     njev: 6\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-50])\n",
    "\n",
    "\n",
    "def func(x: NDArrayFloat) -> float:\n",
    "    return x + np.exp(-10 * x)\n",
    "\n",
    "\n",
    "# result = minimize(func, x0=10, method='L-BFGS-B',\n",
    "#                 options={'maxls': 5, 'disp': 1})\n",
    "\n",
    "\n",
    "def jac(x: NDArrayFloat) -> NDArrayFloat:\n",
    "    return 1.0 - 10 * np.exp(-10 * x)\n",
    "\n",
    "\n",
    "res = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=func,\n",
    "    jac=jac,\n",
    "    maxls=5,\n",
    "    is_check_factorizations=True,\n",
    "    logger=solver_logger,\n",
    "    iprint=100,\n",
    ")\n",
    "solver_logger.info(res)\n",
    "# assert res.message == \"RESTART_FROM_LNSRCH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lbfgsb.types import NDArrayFloat  # for type hints, numpy array of floats\n",
    "from lbfgsb.benchmarks import rosenbrock, rosenbrock_grad\n",
    "\n",
    "\n",
    "lb = np.array([-2, -2])  # lower bounds\n",
    "ub = np.array([2, 2])  # upper bounds\n",
    "bounds = np.array((l, u)).T  # The number of variables to optimize is len(bounds)\n",
    "x0 = np.array([-0.8, -1])  # The initial guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 5.834035727637504e-07\n",
       "        x: [ 9.994e-01  9.989e-01]\n",
       "      nit: 16\n",
       "      jac: [-2.171e-02  1.030e-02]\n",
       "     nfev: 19\n",
       "     njev: 19\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lbfgsb import minimize_lbfgsb\n",
    "\n",
    "res = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=rosenbrock,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    ftol=1e-5,\n",
    "    gtol=1e-5,\n",
    "    maxcor=10,\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT\n",
       "  success: True\n",
       "   status: 1\n",
       "      fun: 0.8619211711864526\n",
       "        x: [ 6.370e-01  4.913e-01]\n",
       "      nit: 1\n",
       "      jac: [-2.250e+01  1.709e+01]\n",
       "     nfev: 3\n",
       "     njev: 3\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_3_fun = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=rosenbrock,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    ftol=1e-5,\n",
    "    gtol=1e-5,\n",
    "    maxfun=3,\n",
    ")\n",
    "\n",
    "res_3_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 1.349454252016592e-10\n",
       "        x: [ 1.000e+00  1.000e+00]\n",
       "      nit: 14\n",
       "      jac: [ 1.030e-04 -6.267e-05]\n",
       "     nfev: 21\n",
       "     njev: 21\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final = minimize_lbfgsb(\n",
    "    x0=res_3_fun.x,\n",
    "    fun=rosenbrock,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    ftol=1e-5,\n",
    "    gtol=1e-5,\n",
    ")\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 5.834035727637504e-07\n",
       "        x: [ 9.994e-01  9.989e-01]\n",
       "      nit: 16\n",
       "      jac: [-2.171e-02  1.030e-02]\n",
       "     nfev: 19\n",
       "     njev: 19\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final = minimize_lbfgsb(\n",
    "    x0=res_3_fun.x,\n",
    "    fun=rosenbrock,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    ftol=1e-5,\n",
    "    gtol=1e-5,\n",
    "    checkpoint=res_3_fun,\n",
    ")\n",
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: STOP: USER CALLBACK\n",
       "  success: True\n",
       "   status: 2\n",
       "      fun: 0.08537354414890938\n",
       "        x: [ 7.354e-01  5.284e-01]\n",
       "      nit: 8\n",
       "      jac: [ 3.115e+00 -2.478e+00]\n",
       "     nfev: 10\n",
       "     njev: 10\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import OptimizeResult\n",
    "\n",
    "\n",
    "def my_custom_callback(\n",
    "    xk: np.typing.NDArray[np.float64], state: OptimizeResult\n",
    ") -> bool:\n",
    "    # if the objective function has been called 10 times or more => stop\n",
    "    if state.nfev >= 10:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "res_callback = minimize_lbfgsb(\n",
    "    x0=x0,\n",
    "    fun=rosenbrock,\n",
    "    jac=rosenbrock_grad,\n",
    "    bounds=bounds,\n",
    "    ftol=1e-5,\n",
    "    gtol=1e-5,\n",
    "    callback=my_custom_callback,\n",
    ")\n",
    "res_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High dimentional rosenbrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function lbfgsb.benchmarks.rosenbrock(x: numpy.ndarray[tuple[typing.Any, ...], numpy.dtype[numpy.float64]]) -> float>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0\n",
    "rosenbrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = np.array([-2, -2])  # lower bounds\n",
    "ub = np.array([2, 2])  # upper bounds\n",
    "bounds = np.array((lb, ub)).T  # The number of variables to optimize is len(bounds)\n",
    "x0 = np.array([-0.8, -1])  # The initial guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000_000\n",
    "x0_large = np.repeat(x0, n)\n",
    "bounds_large = np.tile(bounds, n).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(272199999.99999994),\n",
       " array([-528.4, -528.4, -528.4, ..., -328. , -328. , -328. ],\n",
       "       shape=(2000000,)))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numdifftools as nd\n",
    "\n",
    "\n",
    "def rosenbrock_large(x: NDArrayFloat) -> float:\n",
    "    return np.sum(rosenbrock(x.reshape(2, -1)))\n",
    "\n",
    "\n",
    "def rosenbrock_large_grad(x: NDArrayFloat) -> NDArrayFloat:\n",
    "    return rosenbrock_grad(x.reshape(2, -1)).ravel()\n",
    "\n",
    "\n",
    "# np.testing.assert_allclose(\n",
    "#     rosenbrock_large_grad(x0_large), nd.Gradient(rosenbrock_large, step=1e-5)(x0_large), atol=1e-5, rtol=1e-5\n",
    "# )\n",
    "\n",
    "rosenbrock_large(x0_large), rosenbrock_large_grad(x0_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
       "  success: True\n",
       "   status: 1\n",
       "      fun: 1.5703252811463446e-06\n",
       "        x: [ 1.000e+00  1.000e+00 ...  1.000e+00  1.000e+00]\n",
       "      nit: 19\n",
       "      jac: [ 4.375e-06  4.375e-06 ... -3.429e-06 -3.429e-06]\n",
       "     nfev: 22\n",
       "     njev: 22\n",
       " hess_inv: <2000000x2000000 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_large = minimize_lbfgsb(\n",
    "    x0=x0_large,\n",
    "    fun=rosenbrock_large,\n",
    "    jac=rosenbrock_large_grad,\n",
    "    bounds=bounds_large,\n",
    "    ftol=1e-5,\n",
    "    gtol=1e-5,\n",
    "    is_use_numba_jit=True,\n",
    ")\n",
    "res_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "cmd = \"\"\"\n",
    "res_large = minimize_lbfgsb(\n",
    "    x0=x0_large,\n",
    "    fun=rosenbrock_large,\n",
    "    jac=rosenbrock_large_grad,\n",
    "    bounds=bounds_large,\n",
    "    ftol=1e-5,\n",
    "    gtol=1e-5,\n",
    "    is_use_numba_jit=False\n",
    ")\"\"\"\n",
    "cProfile.run(cmd, \"bench.perf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 1.570325215345258e-06\n",
       "        x: [ 1.000e+00  1.000e+00 ...  1.000e+00  1.000e+00]\n",
       "      nit: 19\n",
       "      jac: [ 4.375e-06  4.375e-06 ... -3.429e-06 -3.429e-06]\n",
       "     nfev: 22\n",
       "     njev: 22\n",
       " hess_inv: <2000000x2000000 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_large = minimize(\n",
    "    x0=x0_large,\n",
    "    fun=rosenbrock_large,\n",
    "    jac=rosenbrock_large_grad,\n",
    "    bounds=bounds_large,\n",
    "    options=dict(\n",
    "        ftol=1e-5,\n",
    "        gtol=1e-5,\n",
    "    ),\n",
    ")\n",
    "res_large"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
